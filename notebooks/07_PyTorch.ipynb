{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_PyTorch",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "bOChJSNXtC9g"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "OLIxEDq6VhvZ"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/LisonEvf/practicalAI-cn/master/images/logo.png\" width=150>\n",
        "\n",
        "在这节课中，我们将学习PyTorch，它是一个用于构建动态神经网络的学习库。我们将在本课程中了解其基础知识，以及如何创建和使用张量（Tensor），而我们将在下一课中使用它制作模型。\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/LisonEvf/practicalAI-cn/master/images/pytorch.png\" width=300>"
      ]
    },
    {
      "metadata": {
        "id": "VoMq0eFRvugb"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensor 基础知识"
      ]
    },
    {
      "metadata": {
        "id": "0-dXQiLlTIgz",
        "outputId": "db34cbc8-672e-4513-90a2-4aeb02ebe34a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# 安装PyTorch库\n",
        "!pip3 install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "t6z1cCPTZSwo"
      },
      "cell_type": "markdown",
      "source": [
        ">  注意：上述安装PyTorch的方式与官网并不一致，因为这里是基于Colab云端安装的，而大家一般是使用pip或者conda来安装PyTorch。具体安装教程参考：https://pytorch.org/"
      ]
    },
    {
      "metadata": {
        "id": "rX7Vs1JxL9wX"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nv0xryLkKujV",
        "outputId": "2ce4c78d-b008-44fb-e7a8-cca0749756b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# 创建一个张量\n",
        "x = torch.Tensor(3, 4)\n",
        "print(\"Type: {}\".format(x.type()))\n",
        "print(\"Size: {}\".format(x.shape))\n",
        "print(\"Values: \\n{}\".format(x))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[2.1707e-18, 7.0952e+22, 1.7748e+28, 1.8176e+31],\n",
            "        [7.2708e+31, 5.0778e+31, 3.2608e-12, 1.7728e+28],\n",
            "        [7.0367e+22, 2.1715e-18, 1.0487e+21, 2.1392e+23]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3)"
      ],
      "metadata": {
        "id": "lSzPsS3YJ8R3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vnyzY4PHL7c5",
        "outputId": "551e96fb-edab-4a29-f046-2bd17b05df78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# 创建一个随机张量\n",
        "x = torch.randn(2, 3) # torch.randn对应于正态分布，而rand(2,3)对应于均匀分布\n",
        "print (x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2826, -2.0357, -1.6480],\n",
            "        [ 0.7468, -1.1572,  0.4160]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DVwGNeKxMXI8",
        "outputId": "447bec04-dadc-460d-89fc-cc2d06bac5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "# 0和1张量\n",
        "x = torch.zeros(2, 3)\n",
        "print (x)\n",
        "x = torch.ones(2, 3)\n",
        "print (x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BPjHnDmCMXLm",
        "outputId": "e0a0a80e-6c6b-4e07-d9f0-8a83a7283a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "# 列表（List） → 张量\n",
        "x = torch.Tensor([[1, 2, 3],[4, 5, 6]])\n",
        "print(\"Size: {}\".format(x.shape))\n",
        "print(\"Values: \\n{}\".format(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mG4-CHkgMXOE",
        "outputId": "4258a024-6f69-42a2-c42a-8747fac8458d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "# NumPy 数组 → 张量\n",
        "x = torch.from_numpy(np.random.rand(2, 3))\n",
        "print(\"Size: {}\".format(x.shape))\n",
        "print(\"Values: \\n{}\".format(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.0632, 0.4443, 0.9658],\n",
            "        [0.4391, 0.9068, 0.6760]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L8X2-5cqMXRA",
        "outputId": "78351b75-3baa-4aef-83e0-a04bd58213b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# 改变张量类型（张量默认为float类型）\n",
        "x = torch.Tensor(3, 4)\n",
        "print(\"Type: {}\".format(x.type()))\n",
        "x = x.long()\n",
        "print(\"Type: {}\".format(x.type()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Type: torch.LongTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S2BRPaMvPbe3"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensor 运算"
      ]
    },
    {
      "metadata": {
        "id": "Xrn8I76TMXT1",
        "outputId": "009a5444-3b28-4f07-d20e-c0e67111c6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "# 加法\n",
        "x = torch.randn(2, 3)\n",
        "y = torch.randn(2, 3)\n",
        "z = x + y\n",
        "print(\"Size: {}\".format(z.shape))\n",
        "print(\"Values: \\n{}\".format(z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.7976,  0.3528,  2.3146],\n",
            "        [-1.6895,  1.9033, -1.0576]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "157fC9WsMXWf",
        "outputId": "ad90d3b9-fbcc-4028-9eba-9371869f710c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "# 向量点积\n",
        "x = torch.randn(2, 3)\n",
        "y = torch.randn(3, 2)\n",
        "z = torch.mm(x, y)\n",
        "print(\"Size: {}\".format(z.shape))\n",
        "print(\"Values: \\n{}\".format(z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[ 0.3005, -2.8694],\n",
            "        [ 1.5858, -3.1363]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G6316lAmMXZG",
        "outputId": "d79058de-5148-45d8-bea4-dbe0fe0335e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "cell_type": "code",
      "source": [
        "# 转置\n",
        "x = torch.randn(2, 3)\n",
        "print(\"Size: {}\".format(x.shape))\n",
        "print(\"Values: \\n{}\".format(x))\n",
        "y = torch.t(x)\n",
        "print(\"Size: {}\".format(y.shape))\n",
        "print(\"Values: \\n{}\".format(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.2164,  0.5022,  0.8684],\n",
            "        [-0.7384,  0.9556,  1.0076]])\n",
            "Size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[ 0.2164, -0.7384],\n",
            "        [ 0.5022,  0.9556],\n",
            "        [ 0.8684,  1.0076]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FCgDCOCjMXcF",
        "outputId": "be2708da-4378-4e4f-e3fa-dee9b99ee764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "# Reshape\n",
        "z = x.view(3, 2)\n",
        "print(\"Size: {}\".format(z.shape))\n",
        "print(\"Values: \\n{}\".format(z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[ 0.2164,  0.5022],\n",
            "        [ 0.8684, -0.7384],\n",
            "        [ 0.9556,  1.0076]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T3-6nGgvECH9",
        "outputId": "a2bfc523-8188-4575-89ee-646f168c92ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "cell_type": "code",
      "source": [
        "# reshaping的危险（意外后果）\n",
        "x = torch.tensor([\n",
        "    [[1,1,1,1], [2,2,2,2], [3,3,3,3]],\n",
        "    [[10,10,10,10], [20,20,20,20], [30,30,30,30]]\n",
        "])\n",
        "print(\"Size: {}\".format(x.shape))\n",
        "print(\"Values: \\n{}\\n\".format(x))\n",
        "a = x.view(x.size(1), -1)\n",
        "print(\"Size: {}\".format(a.shape))\n",
        "print(\"Values: \\n{}\\n\".format(a))\n",
        "b = x.transpose(0,1).contiguous()\n",
        "print(\"Size: {}\".format(b.shape))\n",
        "print(\"Values: \\n{}\\n\".format(b))\n",
        "c = b.view(b.size(0), -1)\n",
        "print(\"Size: {}\".format(c.shape))\n",
        "print(\"Values: \\n{}\".format(c))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 3, 4])\n",
            "Values: \n",
            "tensor([[[ 1,  1,  1,  1],\n",
            "         [ 2,  2,  2,  2],\n",
            "         [ 3,  3,  3,  3]],\n",
            "\n",
            "        [[10, 10, 10, 10],\n",
            "         [20, 20, 20, 20],\n",
            "         [30, 30, 30, 30]]])\n",
            "\n",
            "Size: torch.Size([3, 8])\n",
            "Values: \n",
            "tensor([[ 1,  1,  1,  1,  2,  2,  2,  2],\n",
            "        [ 3,  3,  3,  3, 10, 10, 10, 10],\n",
            "        [20, 20, 20, 20, 30, 30, 30, 30]])\n",
            "\n",
            "Size: torch.Size([3, 2, 4])\n",
            "Values: \n",
            "tensor([[[ 1,  1,  1,  1],\n",
            "         [10, 10, 10, 10]],\n",
            "\n",
            "        [[ 2,  2,  2,  2],\n",
            "         [20, 20, 20, 20]],\n",
            "\n",
            "        [[ 3,  3,  3,  3],\n",
            "         [30, 30, 30, 30]]])\n",
            "\n",
            "Size: torch.Size([3, 8])\n",
            "Values: \n",
            "tensor([[ 1,  1,  1,  1, 10, 10, 10, 10],\n",
            "        [ 2,  2,  2,  2, 20, 20, 20, 20],\n",
            "        [ 3,  3,  3,  3, 30, 30, 30, 30]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hRtG5LShMXew",
        "outputId": "60350550-09c2-4894-e652-e51072f8ef5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "cell_type": "code",
      "source": [
        "# 维度操作\n",
        "x = torch.randn(2, 3)\n",
        "print(\"Values: \\n{}\".format(x))\n",
        "y = torch.sum(x, dim=0) # 为每列添加各行叠加的值\n",
        "print(\"Values: \\n{}\".format(y))\n",
        "z = torch.sum(x, dim=1) # 为每行添加各列叠加的值\n",
        "print(\"Values: \\n{}\".format(z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values: \n",
            "tensor([[-2.2913,  0.1027, -0.3427],\n",
            "        [ 0.7189,  0.4223, -0.0364]])\n",
            "Values: \n",
            "tensor([-1.5724,  0.5250, -0.3791])\n",
            "Values: \n",
            "tensor([-2.5313,  1.1048])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zI0ZV45PrYmw"
      },
      "cell_type": "markdown",
      "source": [
        "# 索引，切片和级联"
      ]
    },
    {
      "metadata": {
        "id": "iM3UFrs0MXhL",
        "outputId": "11a9c76d-ea38-4bf6-e6c3-fb4ccc70feec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        }
      },
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 4)\n",
        "print(\"x: \\n{}\".format(x))\n",
        "print (\"x[:1]: \\n{}\".format(x[:1]))\n",
        "print (\"x[:1, 1:3]: \\n{}\".format(x[:1, 1:3]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: \n",
            "tensor([[ 0.5660,  1.3207,  0.6355,  0.4770],\n",
            "        [-1.5738, -1.6227,  0.1413, -1.8778],\n",
            "        [-0.0666, -0.2320, -0.3943, -0.4921]])\n",
            "x[:1]: \n",
            "tensor([[0.5660, 1.3207, 0.6355, 0.4770]])\n",
            "x[:1, 1:3]: \n",
            "tensor([[1.3207, 0.6355]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_tbpwGxcMXj0",
        "outputId": "ebe7ce15-842d-4bff-fba6-e7d8165c91b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        }
      },
      "cell_type": "code",
      "source": [
        "# 选择维度索引\n",
        "x = torch.randn(2, 3)\n",
        "print(\"Values: \\n{}\".format(x))\n",
        "col_indices = torch.LongTensor([0, 2])\n",
        "chosen = torch.index_select(x, dim=1, index=col_indices) # 第0和第2列的值\n",
        "print(\"Values: \\n{}\".format(chosen))\n",
        "row_indices = torch.LongTensor([0, 1])\n",
        "chosen = x[row_indices, col_indices] # 来自（0,0）和（2,1）的值\n",
        "print(\"Values: \\n{}\".format(chosen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values: \n",
            "tensor([[ 1.7797, -1.2580, -0.6378],\n",
            "        [-1.3466, -0.2311,  0.8040]])\n",
            "Values: \n",
            "tensor([[ 1.7797, -0.6378],\n",
            "        [-1.3466,  0.8040]])\n",
            "Values: \n",
            "tensor([1.7797, 0.8040])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tMeqSQtuMXmH",
        "outputId": "c5560c19-806d-4678-8339-7ca341174d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        }
      },
      "cell_type": "code",
      "source": [
        "# 级联\n",
        "x = torch.randn(2, 3)\n",
        "print(\"Values: \\n{}\".format(x))\n",
        "y = torch.cat([x, x], dim=0) # 按行堆叠（dim = 1按列堆叠）\n",
        "print(\"Values: \\n{}\".format(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values: \n",
            "tensor([[-0.4772,  0.7716,  2.2474],\n",
            "        [ 1.3227, -0.4346,  1.1521]])\n",
            "Values: \n",
            "tensor([[-0.4772,  0.7716,  2.2474],\n",
            "        [ 1.3227, -0.4346,  1.1521],\n",
            "        [-0.4772,  0.7716,  2.2474],\n",
            "        [ 1.3227, -0.4346,  1.1521]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JqiDuIC-ByvO"
      },
      "cell_type": "markdown",
      "source": [
        "# 梯度"
      ]
    },
    {
      "metadata": {
        "id": "qxpGB7-VL7fs",
        "outputId": "b33ec033-9f90-4911-80c1-730c3a775128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        }
      },
      "cell_type": "code",
      "source": [
        "# 带有gradient bookkeeping的张量\n",
        "x = torch.rand(3, 4, requires_grad=True)\n",
        "y = 3*x + 2\n",
        "z = y.mean()\n",
        "z.backward() # z是标量\n",
        "print(\"Values: \\n{}\".format(x))\n",
        "print(\"x.grad: \\n\", x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values: \n",
            "tensor([[0.9651, 0.9546, 0.2183, 0.5656],\n",
            "        [0.2327, 0.4397, 0.7654, 0.8600],\n",
            "        [0.5148, 0.8122, 0.1790, 0.7555]], requires_grad=True)\n",
            "x.grad: \n",
            " tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uf7htaAMDcRV"
      },
      "cell_type": "markdown",
      "source": [
        "* $ y = 3x + 2 $\n",
        "* $ z = \\sum{y}/N $\n",
        "* $ \\frac{\\partial(z)}{\\partial(x)} = \\frac{\\partial(z)}{\\partial(y)} \\frac{\\partial(z)}{\\partial(x)} = \\frac{1}{N} * 3 = \\frac{1}{12} * 3 = 0.25 $"
      ]
    },
    {
      "metadata": {
        "id": "VQtpZh1YD-kz"
      },
      "cell_type": "markdown",
      "source": [
        "# CUDA 张量"
      ]
    },
    {
      "metadata": {
        "id": "E_C3en05L7iT",
        "outputId": "bbe1e507-598c-4089-ee77-2b4cce9d64bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# CUDA可用吗？\n",
        "print (torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "za47KWEJ6en2"
      },
      "cell_type": "markdown",
      "source": [
        "如果上面的代码返回False，那么请转到菜单栏上的`Runtime`→`Change runtime type`并在`Hardware accelerator`下选择`GPU`。"
      ]
    },
    {
      "metadata": {
        "id": "BY2DdN3j6ZxO",
        "outputId": "e637aa7f-d685-4d9a-f453-7f0718d1b009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 创建一个CPU版的0张量\n",
        "x = torch.Tensor(3, 4).to(\"cpu\")\n",
        "print(\"Type: {}\".format(x.type()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EcmdTggzEFPi",
        "outputId": "20fcc79d-6b4e-4c75-8acf-c5e4c2a76786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 创建一个CUDA版的0张量\n",
        "x = torch.Tensor(3, 4).to(\"cuda\")\n",
        "print(\"Type: {}\".format(x.type()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: torch.cuda.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iD-JUbH4hgt7"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}